# Google Maps Scraper

## Overview

The Google Maps Scraper automatically extracts business information from Google Maps using the search query URLs generated by the Query Generator.

## Features

- **CSV Upload**: Upload CSV files containing Google Maps search URLs
- **Configurable Settings**:
  - Max results per search (10-50)
  - Delay between requests (1-5 seconds)
  - Headless or visible browser mode
- **Real-time Progress**: Live updates during scraping
- **Data Extraction**: Captures:
  - Business name
  - Phone number
  - Website URL
  - Rating & review count
  - Full address
  - Business category
- **CSV Export**: Download results for next pipeline step

## How It Works

1. **Upload CSV**: Upload the queries CSV from Query Generator
2. **Configure**: Set max results, delay, and headless mode
3. **Start Scraping**: Click "Start Scraping" to begin
4. **Monitor Progress**: Watch real-time progress bar
5. **Download Results**: Get CSV with all scraped businesses

## Usage

### From Dashboard

1. Navigate to Dashboard
2. Click "Maps Scraper" card
3. Upload your queries CSV
4. Configure settings
5. Start scraping

### Settings Recommendations

**Max Results per Search:**

- 10: Fast, fewer businesses
- 20: **Recommended** - Good balance
- 30-50: Comprehensive but slower

**Delay Between Requests:**

- 1s: Fast but may trigger rate limits
- 2s: **Recommended** - Safe and efficient
- 3-5s: Very safe for large jobs

**Headless Mode:**

- ✅ Checked (default): Runs in background, faster
- ❌ Unchecked: Shows browser window, helpful for debugging

## Technical Details

### API Endpoint

```
POST /api/maps-scraper
```

**Request Body:**

```json
{
  "csvFile": "downloads/queries_123.csv",
  "maxResults": 20,
  "delay": 2,
  "headless": true
}
```

**Response:**

```json
{
  "success": true,
  "jobId": "scrape_1234567890_abc123",
  "count": 245,
  "businesses": [...],
  "downloadUrl": "/downloads/scrape_1234567890_abc123_results.csv"
}
```

### Python Script

Location: `python/scrape_google_maps.py`

Uses Selenium WebDriver to:

1. Open Google Maps search URL
2. Scroll results to load more businesses
3. Click each business card
4. Extract details from sidebar
5. Save to CSV

## Requirements

### Python Dependencies

```bash
pip install selenium webdriver-manager
```

### Chrome Browser

Chrome must be installed for Selenium to work.

## Tips

- Start with small batches (5-10 queries) to test
- Use 2-3 second delays to avoid rate limiting
- Headless mode is faster and uses less resources
- Save results periodically for large jobs
- Google Maps may block aggressive scraping

## Troubleshooting

### "Scraping failed" Error

- Ensure Python is installed and in PATH
- Install required packages: `pip install selenium webdriver-manager`
- Check Chrome is installed

### No Results Found

- Verify CSV has `google_maps_url` column
- Check URLs are valid Google Maps search links
- Try with visible browser (headless = false) to debug

### Rate Limited

- Increase delay between requests
- Reduce max results per search
- Add longer pauses in Python script

## Next Steps

After scraping:

1. Download CSV results
2. Proceed to **Data Cleaner** to remove duplicates
3. Use **Website Separator** to filter businesses
4. Continue with email scraping and AI analysis

## File Structure

```
src/
├── app/
│   ├── (dashboard)/
│   │   └── maps-scraper/
│   │       └── page.tsx          # Frontend UI
│   └── api/
│       ├── maps-scraper/
│       │   └── route.ts           # API endpoint
│       └── upload/
│           └── route.ts           # File upload handler
python/
└── scrape_google_maps.py          # Selenium scraper
```

## Security Notes

- File uploads are saved to `public/downloads/`
- Old files should be cleaned up periodically
- Consider implementing authentication checks
- Rate limiting recommended for production

## Future Enhancements

- [ ] Pause/Resume functionality
- [ ] Background job queue (Bull/BullMQ)
- [ ] Real-time WebSocket updates
- [ ] Retry failed scrapes
- [ ] Proxy rotation support
- [ ] Save jobs to database
- [ ] Email notifications on completion
